{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Big Data Economics</font></center>\n",
    "### <center>Model Selection</center>\n",
    "#### <center>Ali Habibnia</center>\n",
    "\n",
    "<center> Assistant Professor, Department of Economics, </center>\n",
    "<center> and Division of Computational Modeling & Data Analytics at Virginia Tech</center>\n",
    "<center> habibnia@vt.edu </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readings:\n",
    "\n",
    "1. ***Chapter 6,*** Graham Elliott, and Allan Timmermann, Economic Forecasting, Princeton University Press, 2016.\n",
    "2. ***Chapter 7.5 - 7.6 - 7.7,*** [The Elements of Statistical Learning: Data Mining, Inference, and Prediction](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### <center>Frequentism vs Bayesianism</center>\n",
    "\n",
    "One of the initial concepts introduced to scientists in the field of statistics is the existence of two distinct methodologies: frequentism and Bayesianism. The core of the debate between frequentists and Bayesians lies in their differing interpretations of what probability signifies. In our big data class, the majority of the topics will be centered around the frequentist approach. However, time permitting, we might delve into Bayesian methodologies, such as Bayesian Vector Autoregression (B-VAR).\n",
    "\n",
    "<img src=\"images/bayvsfre.jpg\"  width=\"600\">\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of Bayesian Statistics\n",
    "\n",
    "Just as a quick reveiw, Bayesian statistics is a subset of statistics in which probability expresses a degree of belief in an event. This belief may change as new evidence is presented. Bayesian statistics uses Bayes' Theorem to update the probabilities of hypotheses as more evidence or information becomes available.\n",
    "\n",
    "\n",
    "\n",
    "#### Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem provides a way to update our probability estimates for hypotheses as we gain new evidence. It is expressed as:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is the **posterior probability**: The probability of event A occurring given that B is true.\n",
    "- $P(B|A)$ is the **likelihood**: The probability of observing event B given A is true.\n",
    "- $P(A)$ is the **prior probability**: The initial probability of event A before observing B.\n",
    "- $P(B)$ is the **evidence**: The total probability of observing event B under all possible conditions.\n",
    "\n",
    "#### Relation to Conditional Probability\n",
    "\n",
    "Conditional probability is the probability of an event occurring given that another event has already occurred. Bayes' Theorem uses conditional probability to reverse the conditionality:\n",
    "\n",
    "- From $P(B|A)$, the probability of B given A, we can compute $P(A|B)$, the probability of A given B, by incorporating our prior belief about A ($P(A)$) and normalizing by the evidence ($P(B)$).\n",
    "\n",
    "This formula allows us to update our beliefs about the likelihood of hypotheses (A) in light of new evidence (B).\n",
    "\n",
    "\n",
    "#### Applying Bayes' Theorem\n",
    "\n",
    "Bayesian statistics is about updating our beliefs with evidence:\n",
    "\n",
    "1. Start with a prior belief (`P(A)`), which is our initial assumption about the probability of an hypothesis.\n",
    "2. Collect evidence and calculate the likelihood (`P(B|A)`).\n",
    "3. Use Bayes' Theorem to update the prior belief into a posterior belief (`P(A|B)`), which takes into account the new evidence.\n",
    "4. The posterior belief becomes the new prior if more evidence is to be considered, repeating the process.\n",
    "\n",
    "Bayesian statistics is particularly powerful in situations where information is updated or accumulated over time, allowing for dynamic adjustments to predictions and hypotheses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th style=\"text-align:center;\">Aspect</th>\n",
    "<th style=\"text-align:center;\">Frequentist Approach</th>\n",
    "<th style=\"text-align:center;\">Bayesian Approach</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Interpretation of Probability</td>\n",
    "<td style=\"text-align:center;\">Probability is defined as the limit of the relative frequency of an event as the number of trials goes to infinity.</td>\n",
    "<td style=\"text-align:center;\">Probability is interpreted as a measure of belief or certainty about an event.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Parameters</td>\n",
    "<td style=\"text-align:center;\">Parameters are considered fixed but unknown quantities that we aim to estimate.</td>\n",
    "<td style=\"text-align:center;\">Parameters are treated as random variables with their own probability distributions.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Inference</td>\n",
    "<td style=\"text-align:center;\">Inference is made by estimating parameters and assessing the variability of these estimates without using prior information.</td>\n",
    "<td style=\"text-align:center;\">Inference incorporates prior knowledge or beliefs, which are updated with new data through the use of Bayes' theorem.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Confidence vs. Credible Intervals</td>\n",
    "<td style=\"text-align:center;\">Uses confidence intervals, which, in repeated sampling, would contain the true parameter a certain percentage of the time.</td>\n",
    "<td style=\"text-align:center;\">Uses credible intervals, which represent the probability of the parameter lying within a certain range, given the data.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Hypothesis Testing</td>\n",
    "<td style=\"text-align:center;\">Relies on the concept of null hypothesis significance testing (NHST) and p-values to make decisions about hypotheses.</td>\n",
    "<td style=\"text-align:center;\">Focuses on comparing the probabilities of different hypotheses, using the data and prior information.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Decision Making</td>\n",
    "<td style=\"text-align:center;\">Decisions are often based on whether the test statistic falls within a critical region, without incorporating prior information.</td>\n",
    "<td style=\"text-align:center;\">Decisions are made based on the posterior distribution of parameters, taking into account both the data and prior beliefs.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align:center;\">Approach to Data</td>\n",
    "<td style=\"text-align:center;\">Views data as a repeatable random sampleâ€”there is a notion of long-run frequencies in repeated sampling.</td>\n",
    "<td style=\"text-align:center;\">Treats data as fixed and focuses on updating the beliefs about the parameters based on the data observed.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Goals\n",
    "\n",
    "- When we have many variables/predictors (with many possible interactions), it can be difficult to find a good model.\n",
    "- Which main effects do we include?\n",
    "- Which interactions do we include?\n",
    "\n",
    "> Model selection tries to answer to this questions.\n",
    "> we need:\n",
    ">- a criterion or benchmark to compare two models.\n",
    ">- a search strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting vs Model Selection\n",
    "\n",
    "The difference between *model fitting* and *model selection* is often a cause of confusion.\n",
    "**Model fitting** proceeds by assuming a particular model is true, and tuning the model so it provides the best possible fit to the data. **Model selection** (which includes *model comparison*, and *model evaluation*) , on the other hand, asks the larger question of whether the assumptions of the model are compatible with the data.\n",
    "\n",
    "Let's make this more concrete.\n",
    "By *model* here I essentially mean a formula, usually with tunable parameters, which quantifies the likelihood of observing your data.\n",
    "For example, your model might consist of the statement, \"the $(x, y)$ observations come from a straight line, with known normal measurement errors $\\sigma_y$\".\n",
    "Labeling this model $M_1$, we can write:\n",
    "\n",
    "$$\n",
    "y_{M_1}(x;\\theta) = \\theta_0 + \\theta_1 x\\\\\n",
    "y \\sim \\mathcal{N}(y_{M_1}, \\sigma_y^2)\n",
    "$$\n",
    "\n",
    "where the second line indicates that the observed $y$ is normally distributed about the model value, with variance $\\sigma_y^2$.\n",
    "There are two tunable parameters to this model, represented by the vector $\\theta = [\\theta_0, \\theta_1]$ (i.e. the slope and intercept).\n",
    "\n",
    "Another model might consist of the statement \"the observations $(x, y)$ come from a quadratic curve, with known normal measurement errors $\\sigma_y$\".\n",
    "Labeling this model $M_2$, we can write:\n",
    "\n",
    "$$\n",
    "y_{M_2}(x;\\theta) = \\theta_0 + \\theta_1 x + \\theta_2 x^2\\\\\n",
    "y \\sim \\mathcal{N}(y_{M_2}, \\sigma_y^2)\n",
    "$$\n",
    "\n",
    "There are three tunable parameters here, again represented by the vector $\\theta$.\n",
    "\n",
    "Model fitting, in this case, is the process of finding constraints on the values of the parameters $\\theta$ within each model.\n",
    "That is, it allows you to make statements such as, \"assuming $M_1$ is true, this particular $\\theta$ gives the best-fit line\" or \"assuming $M_2$ is true, this particular vector $\\theta$ gives the best-fit curve.\"\n",
    "Model fitting proceeds without respect to whether the model is capable of describing the data well; it just arrives at the best-fit model *under the assumption that the model is accurate*.\n",
    "\n",
    "> Model selection, on the other hand, is not concerned with the parameters themselves, but with the question of whether the model is capable of describing the data well.\n",
    "That is, it allows you to say, \"for my data, a line ($M_1$) provides a better fit than a quadratic curve ($M_2$)\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In particular, we wish to select the model that performs optimally, both with respect to the training data (in-sample data) and to external data (out-of-sample).\n",
    "\n",
    "\n",
    "- How many variables should be included in the model? Here's one idea:\n",
    "  <br>  \n",
    "    - Try different models, and only keep predictors in the model if they have small p-values. (Stepwise regression, our next session topic!)\n",
    "    - Check whether the adjusted R-squared value goes up when you add new predictors.\n",
    "\n",
    "- What functional form should be used in fitting the model?\n",
    "- What sort of polynomial relationship best describes the relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Advertising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a DataFrame\n",
    "data = pd.read_csv('https://www.statlearning.com/s/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shape of the DataFrame\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    7.032594\n",
       "TV           0.047537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the standard import if you're using \"formula notation\" (similar to R)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# create a fitted model in one line\n",
    "lm = smf.ols(formula='sales ~ TV', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>6.129719</td>\n",
       "      <td>7.935468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>0.042231</td>\n",
       "      <td>0.052843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "Intercept  6.129719  7.935468\n",
       "TV         0.042231  0.052843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confidence intervals for the model coefficients\n",
    "lm.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    1.406300e-35\n",
       "TV           1.467390e-42\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the p-values for the model coefficients\n",
    "lm.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611875050850071"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the R-squared value for the model\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    2.938889\n",
       "TV           0.045765\n",
       "radio        0.188530\n",
       "newspaper   -0.001037\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a fitted model with all three features\n",
    "lm = smf.ols(formula='sales ~ TV + radio + newspaper', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972106381789522"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the R-squared value for the model\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    1.267295e-17\n",
       "TV           1.509960e-81\n",
       "radio        1.505339e-54\n",
       "newspaper    8.599151e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the p-values for the model coefficients\n",
    "lm.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Jan 2024</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:12:15</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      sales       & \\textbf{  R-squared:         } &     0.897   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.896   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     570.3   \\\\\n",
       "\\textbf{Date:}             & Wed, 31 Jan 2024 & \\textbf{  Prob (F-statistic):} &  1.58e-96   \\\\\n",
       "\\textbf{Time:}             &     14:12:15     & \\textbf{  Log-Likelihood:    } &   -386.18   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     780.4   \\\\\n",
       "\\textbf{Df Residuals:}     &         196      & \\textbf{  BIC:               } &     793.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       2.9389  &        0.312     &     9.422  &         0.000        &        2.324    &        3.554     \\\\\n",
       "\\textbf{TV}        &       0.0458  &        0.001     &    32.809  &         0.000        &        0.043    &        0.049     \\\\\n",
       "\\textbf{radio}     &       0.1885  &        0.009     &    21.893  &         0.000        &        0.172    &        0.206     \\\\\n",
       "\\textbf{newspaper} &      -0.0010  &        0.006     &    -0.177  &         0.860        &       -0.013    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 60.414 & \\textbf{  Durbin-Watson:     } &    2.084  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  151.241  \\\\\n",
       "\\textbf{Skew:}          & -1.327 & \\textbf{  Prob(JB):          } & 1.44e-33  \\\\\n",
       "\\textbf{Kurtosis:}      &  6.332 & \\textbf{  Cond. No.          } &     454.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  sales   R-squared:                       0.897\n",
       "Model:                            OLS   Adj. R-squared:                  0.896\n",
       "Method:                 Least Squares   F-statistic:                     570.3\n",
       "Date:                Wed, 31 Jan 2024   Prob (F-statistic):           1.58e-96\n",
       "Time:                        14:12:15   Log-Likelihood:                -386.18\n",
       "No. Observations:                 200   AIC:                             780.4\n",
       "Df Residuals:                     196   BIC:                             793.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
       "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
       "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
       "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
       "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
       "Kurtosis:                       6.332   Cond. No.                         454.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a summary of the fitted model\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961505479974428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only include TV and Radio in the model\n",
    "lm = smf.ols(formula='sales ~ TV + radio', data=data).fit()\n",
    "lm.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956373316204668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add Newspaper to the model (which we believe has no association with Sales)\n",
    "lm = smf.ols(formula='sales ~ TV + radio + newspaper', data=data).fit()\n",
    "lm.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048.687962269444"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only include TV and Radio in the model\n",
    "lm = smf.ols(formula='sales ~ TV', data=data).fit()\n",
    "lm.bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788.2890508023245"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only include TV and Radio in the model\n",
    "lm = smf.ols(formula='sales ~ TV + radio', data=data).fit()\n",
    "lm.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Approach: Comparing Maximum Likelihoods\n",
    "\n",
    "One common mistake is to assume that we can select between models via *the value of the maximum likelihood*.\n",
    "While this works in some special cases, it is not generally applicable. The model with more variables yields a higher log-likelihood, but this **does not** necessarily mean it is the better model!\n",
    "\n",
    "The problem is that when a model has more degrees of freedom, will **always** give an equal or larger maximum likelihood, regardless of the data! This trend holds generally: as you increase model complexity, the maximum likelihood value will (almost) always increase!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing R2 and Adjusted R2\n",
    "\n",
    "**R-squared will always increase as you add more features to the model**, even if they are unrelated to the response. Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
    "\n",
    "There is alternative to R-squared called **adjusted R-squared** that penalizes model complexity.\n",
    "\n",
    "<img src=\"images/regres.png\"  width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Coefficient of Determination (RÂ²):\n",
    "$$ R^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST} $$\n",
    "\n",
    "Sum of Squares Total (SST):\n",
    "$$ SST = \\sum (Y - \\bar{Y})^2 $$\n",
    "\n",
    "Sum of Squares Regression (SSR):\n",
    "$$ SSR = \\sum (\\hat{Y} - \\bar{Y})^2 $$\n",
    "\n",
    "Sum of Squares Error (SSE):\n",
    "$$ SSE = \\sum (Y - \\hat{Y})^2 $$\n",
    "\n",
    "\n",
    "\n",
    "Adjusted R-Squared (\\(R^2_{adjusted}\\)) is calculated as:\n",
    "$$ R^2_{adjusted} = 1 - (1 - R^2) \\frac{(N - 1)}{(N - p - 1)} $$\n",
    "\n",
    "Where:\n",
    "- $R^2$ is the sample R-squared.\n",
    "- $p$ is the number of predictors.\n",
    "- $N$ is the total sample size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information-theoretic Model Selection (AIC and BIC)\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Understand that both AIC and BIC are information criteria that also can be used to perform model selection\n",
    "- Understand how AIC and BIC use likelihood\n",
    "\n",
    "\n",
    "Information criteria (IC) choose models by trading off model fit against a penalty\n",
    "for model complexity as measured by the number of free parameters that have to\n",
    "be estimated for the models. Several information criteria have been suggested in\n",
    "the literature, the two most popular of which are the Bayes information criterion\n",
    "(Schwarz BIC, SBIC, or BIC) proposed by Schwarz (1978) and the Akaike information\n",
    "criterion (AIC) due to Akaike (1974)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information criteria employ different strategies to trade-off fit against parsimony.\n",
    "The Bayesian information criterion selects the model with the highest posterior\n",
    "probability given the data. To choose a single model from the candidate set, the\n",
    "models are ranked according to their posterior probabilities and the model with the\n",
    "highest posterior probability is chosen. The Akaike information criterion seeks to minimize the (Kullbackâ€“Leibler) distance between the density of a candidate model\n",
    "and the density of the true (unknown) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The AIC\n",
    "\n",
    "One approach to model selection is to use an information-theoretic criterion to identify the most appropriate model. Akaike (1973) found a formal relationship between Kullback-Leibler information (a dominant paradigm in information and coding theory) and likelihood theory. Akaike's Information Criterion (AIC) is an estimator of expected relative K-L information based on the maximized log-likelihood function, corrected for asymptotic bias. \n",
    "\n",
    "<br>\n",
    "<center> AIC(model) = -2  $\\cdot$ log-likelihood(model) + 2 $\\cdot$ (length of the parameter space)</center>\n",
    "\n",
    "$$\\text{AIC} = âˆ’2 \\log(L(\\theta|data)) + 2p$$\n",
    "\n",
    "AIC balances the fit of the model (in terms of the likelihood) with the number of parameters required to achieve that fit. We can easily calculate AIC from the residual sums of squares as:\n",
    "\n",
    "$$\\text{AIC} = n \\log(\\text{RSS}/n) + 2p$$\n",
    "\n",
    "where $p$ is the number of parameters in the model. Notice that as the number of parameters increase, the residual sum of squares goes down, but the second term (a penalty) increases.\n",
    "\n",
    "To apply AIC to a model selection problem, we choose the model that has the lowest AIC value.\n",
    "\n",
    "The AIC is generally used to compare each candidate model. The nice thing about the AIC is that for every model that uses Maximum Likelihood Estimation, the log-likelihood is automatically computed, and as a consequence the AIC is very easy to calculate.\n",
    "The AIC acts as a penalised log-likelihood criterion, giving a balance between a good fit (high value of log-likelihood) and complexity (complex models are penalized more than fairly simple ones). The AIC is unbounded so can take any type of value, but the bottom line is that when comparing models, the model with the lowest AIC should be selected.\n",
    "Note that directly comparing the values of log-likelihood maxima for different models (without including the penalty) is not good enough for model comparison, because including more parameters in a model will always give rise to an increased value of the maximum likelihood. Because of that reason, searching for the model with maximal log-likelihood would always lead to the model with the most parameters. The AIC balances this by penalizing for number of parameters, hence searching for models with few parameters but fitting the data well. data well.\n",
    "\n",
    "> It makes rather stringent assumptions about the form of the likelihood, and so cannot be universally applied.\n",
    "\n",
    "#### The BIC\n",
    "\n",
    "The BIC (Bayesian Information Criterion) is very similar to the AIC and emerged as a Bayesian response to the AIC, but can be used for the exact same purposes. The idea is to select the candidate model with the highest probability given the data. This idea can be formalised inside a Bayesian framework, involving prior probabilities on candidate models along with prior densities on all parameters in the models. The penalty is slightly changed and depends on the number of rows to the data set:\n",
    "\n",
    "<br>\n",
    "<center> BIC(model) = -2 $\\cdot$ log-likelihood(model) + log(number of observations) $\\cdot$ (length of the parameter space)</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So is there a better approach to feature selection? **Cross-validation.** It provides a more reliable estimate of out-of-sample error, and thus is a better way to choose which of your models will best **generalize** to out-of-sample data. Importantly, cross-validation can be applied to any model, whereas the methods described above only apply to linear models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
