{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color=navy>Big Data Economics</font></center>\n",
    "### <center>An Overview</center>\n",
    "#### <center>Ali Habibnia</center>\n",
    "\n",
    "    \n",
    "<center> Assistant Professor, Department of Economics, </center>\n",
    "<center> and Division of Computational Modeling & Data Analytics at Virginia Tech</center>\n",
    "<center> habibnia@vt.edu </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<img src=\"images/tech3.jpg\" alt=\"Drawing\" width=\"350\"/>\n",
    "\n",
    "#### The image exemplifies the intersection and collaborative synergy among three pivotal technological domains:\n",
    "\n",
    "1. **Artificial Intelligence and Machine Learning**: AI and ML can leverage Big Alternative Data for developing more sophisticated models and algorithms, which can lead to more accurate predictions and better decision-making.\n",
    "\n",
    "2. **Big Data**: provides the raw information that allows AI models to make informed decisions. This data can be processed and analyzed using machine learning algorithms to uncover insights that were previously not possible with traditional data sources, enhancing research and development across various fields.\n",
    "\n",
    "3. **High-Performance Computing (HPC)**: HPC provides the necessary computational power to handle the vast amounts of data and complex calculations required by AI and ML, thus speeding up research and enabling more complex simulations. \n",
    "\n",
    "The integration of Big Data, AI, and HPC creates a powerful ecosystem for advanced analytics, enabling the tackling of intricate problems and the extraction of profound insights. This triad fosters the capability for real-time analysis and decision-making, revolutionizing sectors such as finance, healthcare, and transportation by improving efficiency and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### The concept of Big Data is often associated with the (?) V's:\n",
    "\n",
    "<img src=\"images/bigdatavs.JPG\" alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "\n",
    "1. **Visualization**: Represents the importance of presenting data in a manner that is easily and immediately understandable.\n",
    "\n",
    "2. **Velocity**: Refers to the speed at which data is generated, processed, and analyzed.\n",
    "\n",
    "3. **Variety**: Indicates the different types of data (structured, unstructured, and semi-structured) that are available for analysis.\n",
    "\n",
    "4. **Variability**: Suggests that data flows can be highly inconsistent with periodic peaks.\n",
    "\n",
    "5. **Volume**: Points to the vast amounts of data generated from various sources.\n",
    "\n",
    "6. **Vulnerability**: Highlights the security concerns and risks associated with managing and storing large quantities of data.\n",
    "\n",
    "7. **Validity**: Concerns the accuracy and correctness of data for the intended use.\n",
    "\n",
    "8. **Volatility**: Describes how long data is valid and how quickly it becomes outdated.\n",
    "\n",
    "9. **Veracity**: Addresses the quality and reliability of data.\n",
    "\n",
    "10. **Value**: Emphasizes the worth of the data being collected and how it can be turned into a valuable resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Big Data?\n",
    "\n",
    "<img src=\"images/model.png\" alt=\"Drawing\"/>\n",
    "\n",
    "Big Data is a term that varies in definition depending on the context and the person you're asking. In the field of econometrics, the concept of Big Data can be framed with respect to the dimensions of the dataset, namely the number of variables and observations.\n",
    "\n",
    "<center>  $  y = X\\beta + \\varepsilon $   </center>\n",
    "<br>\n",
    "<center>  $\\varepsilon \\sim N(0,\\sigma^2) $   </center>\n",
    "<br>\n",
    "<center>  $  L_{OLS}(\\hat\\beta) = \\sum_{i=1}^n (y_i - x_i' \\hat\\beta)^2 = ||y-X'\\beta||^2$   </center>\n",
    "<br>\n",
    "<center>  $\\hat\\beta_{OLS} = (X′X)^{−1}(X′Y) $   </center>\n",
    "\n",
    "<br>\n",
    "<center>  $Bias (\\hat\\beta_{OLS}) = E(\\hat\\beta_{OLS}) - \\beta $   </center>\n",
    "\n",
    "<br>\n",
    "<center>  $Var (\\hat\\beta_{OLS}) = \\sigma^2(X′X)^{−1} $   </center>\n",
    "\n",
    "<center>  $\\sigma^2 = \\frac{\\varepsilon' \\varepsilon}{n-p} $   </center>\n",
    "\n",
    "\n",
    "* **Wild data** (unstructured, constract with Census surveys, or twitter)\n",
    "\n",
    "* **Wide data** (a.k.a Larg-P data because p>>N)\n",
    "\n",
    "* **Long data** (a.k.a Large-N data because N is very large and may not even fit onto a single hard drive)\n",
    "\n",
    "* **Complex model** (a.k.a Large-Theta because model/algorithm has many parameters)\n",
    "\n",
    "<img src=\"images/mlp.png\" alt=\"Drawing\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pillars of Big Data\n",
    "\n",
    "* Foundation of basic calculus, linear algebra, probability analysis, and neumerical optimization)\n",
    "\n",
    "* Programming (for automation of data collection, manipulation, cleaning, visualization, and modeling)\n",
    "\n",
    "* Visualization & exploration\n",
    "\n",
    "* Machine learning (to capture nonlinearity and non normality in data, to compress data, and prediction)\n",
    "\n",
    "* Causal inference (to be able to make policy prescription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlocking New Dimensions: The Pivotal Role of Alternative Data\n",
    "\n",
    "- **Alternative data**: refers to non-traditional data sources that can provide additional insights beyond what's available through conventional data. Its advantages are frequency and near-real-time data, accuracy and objectiveness. Its disadvantages are the fact that the indicators available are merely proxies for what policymakers are interested in and need for policy design. Here are some examples of alternative data and variables:\n",
    "\n",
    "    - **Textual data such as News Headlines**\n",
    "    - **Digital footprints from social media**\n",
    "    - **Mobile phone data**\n",
    "    - **Satellite Imagery** nighttime light measures, or luminosity, as proxies for economic activity and population distribution\n",
    "    - **Search Engine Trends**\n",
    "    - **Environmental, Social, and Governance (ESG) Data**\n",
    "\n",
    "\n",
    "<img src=\"images/text.PNG\" alt=\"Drawing\" width=\"400\"/>\n",
    "<img src=\"images/satt2.jpg\" alt=\"Drawing\" width=\"400\"/>\n",
    "<img src=\"images/satt.jpg\" alt=\"Drawing\" width=\"400\"/>\n",
    "<img src=\"images/satt3.jpg\" alt=\"Drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data: FROM HYPOTHESIS TESTING TO MACHINE LEARNING\n",
    "\n",
    "* Machine learning (ML) allows researchers to analyze data in novel ways. Computers today can process multiple sets of data in little time and, with the correct classification sets, recognize highly complex patterns among them. \n",
    "\n",
    "* Designed to simulate the interactions of biological neurons, “deep learning” uses artificial neural networks to discern features in successive layers of data while iterating on previously recognized trends. \n",
    "\n",
    "\n",
    "### Econometrics vs. Machine Learning\n",
    "\n",
    "#### Goal of econometrics\n",
    "\n",
    "* \"the goal of econometrics is to find β hat\" where here we mean β hat to be the causal impact of X on y\n",
    "\n",
    "* The primary statistical concern of econometrics is sampling error. In other words, the goal is to quantify the uncertainty around β hat due to randomness in the sampling of the population. \n",
    "\n",
    "* The goal is to make counterfactual predictions.\n",
    "\n",
    "        What would happen to Amazon's profits if it changed its website layout?\n",
    "\n",
    "We don't get to observe the world under these alternative policies, so we can't simply find the answers in the data. Knowing the counterfactual requires being able to measure a causal effect. Being able to measure a causal effect requires making assumptions. That's what economics is all about!\n",
    "\n",
    "\n",
    "#### Goal of machine learning\n",
    "\n",
    "* In contrast, the goal of machine learning is to come up with the best possible out-of-sample prediction. \n",
    "\n",
    "* We refer to this as the primary concern of machine learning being \"y hat\"\n",
    "\n",
    "* The goal is to make sure that the best prediction is had by tuning and validating many different kinds of models. This is what cross-validation is all about, and it is what machine learning practitioners obsess about."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
